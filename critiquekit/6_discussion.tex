\section{Discussion \& Future Work}
This chapter empirically investigated two techniques for scaffolding feedback: reusable feedback suggestions and adaptive guidance. This work complements this dissertation more broadly, highlighting the benefits of adaptive guidance for interfaces that support creative tasks. Here we discuss and synthesize the findings.  

\subsection{Generating Reusable Feedback Suggestions}
This work investigated whether suggestions and guidance can scaffold the feedback process. For this strategy to work, an eye towards reuse and adaptive feedback must be adopted. As Sch\"{o}n argues, experts may be most capable of recognizing common patterns and giving useful feedback \cite{schon1984reflective}. However, while feedback should be specific, underlying concepts can generalize across contexts. In the studies that used expert-generated feedback suggestions (Deployment 1 and Experiment 2), participants cited the same reason for why the suggestions were useful: as inspiration. Participants reported that the suggestions helped them find words for their thoughts or helped direct their attention to issues they did not originally notice. This suggests that reusable suggestions should focus attention to common issues rather than specific instances. Our approach demonstrates how expertise on creative work can be scaled by providing feedback on a few to apply to many \cite{kulkarni2013peer}. This extends work on reusable feedback in coding and writing \cite{Brooks2014, Hartmann2010, Head2017} while keeping the human in the loop, enabling novices to learn and reuse expert insights. 

It is possible that more general suggestions can lead to less personalized feedback, particularly in abstract domains like visual design. We observed this in 7 of the 79 comments from the CritiqueKit condition in Experiment 2, in which the four participants simply selected suggestions without further elaboration. A consideration for creating and presenting reusable suggestions is how these suggestions can be both general yet personal to be more helpful to the recipient. 

\subsection{What is the Best Way to Guide Feedback?}
Prior empirical work on feedback (\textit{e.g.}, Kulkarni \textit{et al.} \cite{kulkarni2013peer} and Krause \textit{et al.} \cite{Krause2017}) has not compared static and adaptive suggestions. In this chapter, we found that people rarely used static suggestions and did not find them helpful; adaptive suggestions were used more and found more helpful. This reinforces prior work demonstrating that adaptive presentation of examples can improve learning \cite{Lee2010, Najar2014}. By presenting feedback suggestions that directly addressed missing characteristics of a reviewer's feedback, reviewers were prompted on where they could specifically improve, and explicitly shown examples of how to do so. 

The second experiment adapted feedback suggestions based on whether their feedback was categorized as specific, actionable, and/or justified. Though some of the prototype's categorizations were misleading or inaccurate (for example, the comment ``user flow is simple'' was categorized as ``Is Actionable'' because of the word ``use'', even though it lacks a concrete suggestion), participants still referenced the three categories when composing their comments. The guidance panel was useful as a reminder to include the attributes of good feedback in their comments. A more sophisticated method for categorization would likely be helpful, though our na√Øve approach performed reasonably well overall.

The guidance panel focused on three important attributes of good feedback. A consideration is to also provide guidance for emotional content in feedback, as emotional regulation is important to how learners perceive feedback \cite{Krause2017, Varlander2008}. In addition, other characteristics may also contribute to perceived helpfulness, such as complexity or novelty \cite{Krause2017}, that could be further explored through adaptive guidance.

\subsection{Creating Adaptive Feedback Interfaces}
In order for adaptive guidance to be most effective, the interface should be suitable for adaptation. In the two deployments and first experiment, the suggestions were not curated in any way: more than 1,400 comments were supplied as suggestions, but only 76 of these were reused by reviewers. Having more suggestions available was not beneficial because the suggestions were not sufficiently adaptable and were potentially irrelevant and difficult to browse. Experiment 2 introduced a curated approach: experts provided the suggestions with generalizability in mind. Of the 47 suggestions created, 29 were reused. Though fewer suggestions were available, they were more general and adaptable, potentially making them more useful. 

Suggestion presentation shares many properties with search interfaces. Like with search, a good result needs to not only be in the set, but toward the top of the set \cite{hearst2009search}. The second experiment contained fewer suggestions, enabling easier search and browsing. Effective curation and display of suggestions should take into consideration the quality of feedback suggestions and how likely they are to be selected, potentially using frequency or some measure of generalizability as a signal. 

\subsubsection{Summary}
Looking across the deployments and experiments, adaptive suggestions and interactive guidance significantly improved feedback while static suggestions did not offer significant improvements. These techniques were embodied in the CritiqueKit system, used by 95 feedback providers and 336 recipients. Although CritiqueKit's main goal was to help reviewers produce better outcomes quickly and in the moment, we suspect that the combination of interactive guidance and illustrative examples may also help reviewers learn and retain procedural about writing good feedback. Future work should evaluate this hypothesis and further investigate how best to create, curate, and display helpful suggestions. 

Much knowledge work features both underlying principles and context-specific knowledge of when and how to apply these principles. Potentially applicable feedback and review areas include domains as disparate as hiring and employee reviews, code reviews, product reviews, and reviews of academic papers, screenplays, business plans, and any other domain that blends context-specific creative choices with common genre structures. More generally, this work showed how contextual suggestions and guidance can help improve creative outcomes in the moment by leveraging and reusing existing expert work. We hope that creativity support systems of all stripes will find value in the ideas and results presented here.

\subsubsection{Acknowledgements}
We thank Kandarp Khandwala and Janet Johnson for help rating feedback. This research was supported in part by Adobe Research.

This chapter, in part, includes portions of material as it appears in \textit{Interactive Guidance Techniques for Improving Creative Feedback} by Tricia J. Ngoon, C. Ailie Fraser, Ariel S. Weingarten, Mira Dontcheva, and Scott Klemmer in the Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems (CHI '18). The dissertation author was one of the primary investigators and authors of this paper.
